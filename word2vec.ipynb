{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, median_absolute_error\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('CLEAN.csv',index_col=0)\n",
    "# print(data['misarticulation_index'].values[:15])\n",
    "data = data.loc[data['first_lang_english']==1]\n",
    "data.drop(columns=['first_lang_english'],inplace=True)\n",
    "data = data[['response_text','misarticulation_index']]\n",
    "\n",
    "data['misarticulation_index'] = (data['misarticulation_index']/0.33333).astype(int).astype(float)\n",
    "# print(data['misarticulation_index'].values[:15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 504/504 [00:00<00:00, 2110.31it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "for text in tqdm(data['response_text']):\n",
    "    t_tokens = nltk.word_tokenize(text)\n",
    "    sentences.append(t_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(sentences=sentences, vector_size=300, window=5, min_count=1, workers=8)\n",
    "word_vectors = model.wv\n",
    "word_vectors.save(\"word2vec.wordvectors\")\n",
    "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv.key_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7ff6a164f040>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 504/504 [00:00<00:00, 1686.43it/s]\n"
     ]
    }
   ],
   "source": [
    "text_embs = []\n",
    "for text in tqdm(data['response_text']):\n",
    "    emb = np.array(list(map(lambda x:wv[x], nltk.word_tokenize(text)))).mean(0)\n",
    "    text_embs.append(emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(text_embs)\n",
    "y = data['misarticulation_index'].values\n",
    "\n",
    "split_ = np.random.RandomState(seed=0).permutation(X.shape[0])\n",
    "num_train = int(X.shape[0]*0.7)\n",
    "X_train, X_test, y_train, y_test = X[:num_train,:], X[num_train:,:], y[:num_train], y[num_train:]\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(epsilon=1, kernel='linear')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html 参数可以自己调\n",
    "regr = svm.SVR(kernel='linear', epsilon=1)\n",
    "regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function mean_absolute_error at 0x0000015C48C6A438> 0.8796021936060312\n",
      "<function mean_squared_error at 0x0000015C48C6A168> 1.1963322089436903\n",
      "<function median_absolute_error at 0x0000015C48C645E8> 0.6676408580712971\n"
     ]
    }
   ],
   "source": [
    "#default parameters\n",
    "ms = [mean_absolute_error, mean_squared_error, median_absolute_error]\n",
    "for m in ms:\n",
    "    print(m, m(y_test/3., regr.predict(X_test)/3.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function mean_absolute_error at 0x7ff6d9c49940> 0.8596460255896925\n",
      "<function mean_squared_error at 0x7ff6d9c54310> 1.1724932169336217\n",
      "<function median_absolute_error at 0x7ff6d9c54550> 0.666695209903245\n"
     ]
    }
   ],
   "source": [
    "#tuned model\n",
    "\n",
    "ms = [mean_absolute_error, mean_squared_error, median_absolute_error]\n",
    "for m in ms:\n",
    "    print(m, m(y_test/3., regr.predict(X_test)/3.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
